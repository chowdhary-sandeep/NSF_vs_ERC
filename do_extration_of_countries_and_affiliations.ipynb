{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d016d37a-16ec-4be1-987b-8c81251bad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "my_file = open(\"all_country_codes.txt\", \"r\")\n",
    "all_country_codes = my_file.read()\n",
    "# print(all_country_codes)\n",
    "\n",
    "all_country_codes = all_country_codes.split(\"\\n\")[1:]\n",
    "all_country_codes = [x.split(\",\") for x in all_country_codes]\n",
    "all_country_codes\n",
    "\n",
    "\n",
    "my_file = open(\"eu_codes.txt\", \"r\")\n",
    "eu_codes = my_file.read()\n",
    "eu_codes = eu_codes.split(\"\\n\")\n",
    "eu_codes = [x.split(\"-\") for x in eu_codes]\n",
    "a=[]\n",
    "for x in eu_codes:\n",
    "    b=[]\n",
    "    for y in x:\n",
    "        b.append(y.strip())\n",
    "    a.append(b)\n",
    "eu_codes = [x[0:2] for x in eu_codes]\n",
    "eu_codes_only=[x[1].strip() for x in eu_codes]\n",
    "eu_codes_only.append('GB')\n",
    "eu_codes_only=sorted(eu_codes_only)\n",
    "all_country_codes_only=[x[1].strip() for x in all_country_codes]\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "# print(all_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea520c2-cfcf-4ab5-9ed9-fe397601c75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1619b-49db-4717-a5ca-e7c08c65e148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55ba0ed6-4776-4a2b-ad51-cefe6b8c9f3d",
   "metadata": {},
   "source": [
    "# ERC : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a83468b-c211-4090-8f5f-0adfb3c601a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_ERC_collab_patterns=[]\n",
    "\n",
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# files_=glob.glob(path_data+'dict_careers_ERC50'+'*')\n",
    "# #-----------------------------------------\n",
    "# dict_careers={}\n",
    "# for file in files_:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         dict_careers[file.split('/')[-1]]=pickle.load(f)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe558b14-f65e-4df7-97b4-84d6c3e60e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ad8ab-5d41-4682-8845-139dd40b24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--59---- 0.4957983193277311 652.88--estimated---0.366hourss\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# list_ERC_collab_patterns=[]\n",
    "\n",
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "# #-----------------------------------------\n",
    "# dict_careers={}\n",
    "# for file in files_:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "\n",
    "# it_file=0\n",
    "# #-----------------------------------------        \n",
    "# t_ic = time.time();\n",
    "\n",
    "# for key in dict_careers.keys():     \n",
    "#     it_file=it_file+1\n",
    "#     scientists_nsf=list(dict_careers[key].keys())\n",
    "#     # IT_=11\n",
    "#     # for it_sci in range(IT_,IT_+1):\n",
    "#     for it_sci in range(len(scientists_nsf)):\n",
    "#         sci=scientists_nsf[it_sci]\n",
    "\n",
    "#         x=json.loads(dict_careers[key][sci])\n",
    "#     #     print(sci,', works count=',len(x))\n",
    "#         if x!='NA':\n",
    "#             for it_work in range(len(x)):\n",
    "#                 paper_=x[it_work]\n",
    "#         #         print(paper_.keys(),'\\n\\n')\n",
    "\n",
    "#         #         print(paper_['title'],'\\n')\n",
    "#         #         print('Team size=',len(paper_['authorships']))\n",
    "#         #         print('pub year=',(paper_['publication_year']))\n",
    "#         #         print('cited counts=',(paper_['counts_by_year']))\n",
    "\n",
    "#                 affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#         #         print(affils_,'\\n\\n')\n",
    "#                 countries_=[]\n",
    "#                 store_unis=[]\n",
    "                \n",
    "#                 for insti in affils_:\n",
    "#                     if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "#                         country=insti[0]['country_code']\n",
    "#                         uni=insti[0]['id']\n",
    "#                         countries_.append(country)\n",
    "#                         store_unis.append(uni)\n",
    "                        \n",
    "#         #         print([insti[0]['country_code'] for insti in affils_ if len(insti)>0])\n",
    "#         #         print(countries_)\n",
    "#                 for y in paper_['authorships']:\n",
    "#                     if 'display_name' in y['author'].keys():\n",
    "                        \n",
    "# #                         if y['author']['display_name']==sci:\n",
    "#                         if fuzz.token_sort_ratio(y['author']['display_name'],sci) >80:\n",
    "                            \n",
    "#                             insti_main=y['institutions']\n",
    "#                 try:            \n",
    "#                     if len(insti_main)>0:\n",
    "#                         if 'country_code' in insti_main[0].keys():\n",
    "#                             country_main=insti_main[0]['country_code']\n",
    "#                             uni_main=insti_main[0]['id']\n",
    "#                         else:\n",
    "#                             country_main=None\n",
    "#                             uni_main=None\n",
    "#                     else:\n",
    "#                         country_main=None  \n",
    "#                         uni_main=None\n",
    "#                 except:\n",
    "#                     country_main=None \n",
    "#                     uni_main=None\n",
    "#                 try:\n",
    "#                     del insti_main\n",
    "#                 except:\n",
    "#                     ''                    \n",
    "#                 list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),'countries':countries_,'unis':store_unis,'team_size':len(paper_['authorships']),'pub_year':paper_['publication_year'],'counts_by_year':paper_['counts_by_year'],'country_awardee':country_main,'uni_awardee':uni_main,})\n",
    "# #     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "#     t_oc = time.time();\n",
    "#     progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "\n",
    "# dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "# dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "# countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "# n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "# dfs_ERC['identified_countries']=n_identified\n",
    "# dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "# dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "# dfs_ERC['subtract_from_n_US']=(dfs_ERC['country_awardee']=='US').astype('int')\n",
    "\n",
    "# with open(path_data+'dfs_ERC(nature physics).pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs_ERC.iloc[:,[0,1,2,3,4,6,7]], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae726c9-4e65-4890-b9fd-2204d4ec9210",
   "metadata": {},
   "source": [
    "## only  saving awardee uni and country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba7924-d88b-43dc-977b-ba8c73c25a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_ERC_collab_patterns=[]\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "#-----------------------------------------\n",
    "dict_careers={}\n",
    "for file in files_:\n",
    "    with open(file, 'rb') as f:\n",
    "        dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "\n",
    "it_file=0\n",
    "#-----------------------------------------        \n",
    "t_ic = time.time();\n",
    "\n",
    "for key in dict_careers.keys():     \n",
    "    it_file=it_file+1\n",
    "    scientists_nsf=list(dict_careers[key].keys())\n",
    "    # IT_=11\n",
    "    for it_sci in range(len(scientists_nsf)):\n",
    "        sci=scientists_nsf[it_sci]\n",
    "\n",
    "        x=json.loads(dict_careers[key][sci])\n",
    "    #     print(sci,', works count=',len(x))\n",
    "        if x!='NA':\n",
    "            for it_work in range(len(x)):\n",
    "                paper_=x[it_work]\n",
    "                affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        if fuzz.token_sort_ratio(y['author']['display_name'],sci) >80:\n",
    "                            insti_main=y['institutions']\n",
    "                try:            \n",
    "                    if len(insti_main)>0:\n",
    "                        if 'country_code' in insti_main[0].keys():\n",
    "                            country_main=insti_main[0]['country_code']\n",
    "                            uni_main=insti_main[0]['id']\n",
    "                        else:\n",
    "                            country_main=None\n",
    "                            uni_main=None\n",
    "                    else:\n",
    "                        country_main=None  \n",
    "                        uni_main=None\n",
    "                except:\n",
    "                    country_main=None \n",
    "                    uni_main=None\n",
    "                try:\n",
    "                    del insti_main\n",
    "                except:\n",
    "                    ''                    \n",
    "                list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),'pub_year':paper_['publication_year'],'country_awardee':country_main,'uni_awardee':uni_main,})\n",
    "    t_oc = time.time();\n",
    "    progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "with open(path_data+'dfs_ERC_only_awardee(nature physics).pkl', 'wb') as f:\n",
    "    pickle.dump(dfs_ERC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95608c30-2aa3-4530-bcca-9dd7367aef48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c04f9040-45a4-4bda-9bc4-db4399c85de4",
   "metadata": {},
   "source": [
    "## collecting ERC affiliation strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64a3b97-2d84-4f57-b20e-272e37dfc0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.091596638655462275\r"
     ]
    }
   ],
   "source": [
    "\n",
    "list_ERC_collab_patterns=[]\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "#-----------------------------------------\n",
    "dict_uni_main={}\n",
    "             \n",
    "\n",
    "\n",
    "it_file=0\n",
    "#-----------------------------------------        \n",
    "t_ic = time.time();\n",
    "\n",
    "for file in files_:\n",
    "    with open(file, 'rb') as f:\n",
    "        loaded_file=pickle.load(f)   \n",
    "        \n",
    "    it_file=it_file+1\n",
    "    print(it_file/len(files_),end='\\r')\n",
    "    scientists_nsf=list(loaded_file.keys())\n",
    "    for it_sci in range(len(scientists_nsf)):\n",
    "        sci=scientists_nsf[it_sci]\n",
    "        x=json.loads(loaded_file[sci])\n",
    "        if x!='NA':\n",
    "            for it_work in range(len(x)):\n",
    "                paper_=x[it_work]\n",
    "\n",
    "                affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#                 print(affils_,'\\n\\n')\n",
    "\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        \n",
    "                        if fuzz.token_sort_ratio(y['author']['display_name'],sci) >80:\n",
    "                            \n",
    "                            insti_main=y['institutions']\n",
    "                try:            \n",
    "                    if len(insti_main)>0:\n",
    "                        if 'country_code' in insti_main[0].keys():\n",
    "                            country_main=insti_main[0]['country_code']\n",
    "                            uni_main=insti_main[0]['id']\n",
    "                            dict_uni_main[insti_main[0]['id']]=insti_main[0]['display_name']\n",
    "                        else:\n",
    "                            country_main=None\n",
    "                            uni_main=None\n",
    "                    else:\n",
    "                        country_main=None  \n",
    "                        uni_main=None\n",
    "                except:\n",
    "                    country_main=None \n",
    "                    uni_main=None\n",
    "                try:\n",
    "                    del insti_main\n",
    "                except:\n",
    "                    ''                    \n",
    "\n",
    "with open(path_data+'dict_uni_main(nature physics).pkl', 'wb') as f:\n",
    "    pickle.dump(dict_uni_main, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76357a-5d15-4db3-9ba3-ecf04a493a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6582b5-1cdc-4e85-ab67-0ffefe786bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9afc9f-cd89-4a4f-abd5-271cf0384555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e86330b9-93cf-471c-9e97-c8bf76d77109",
   "metadata": {},
   "source": [
    "# NSF : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fd045-fb61-4c35-a566-89880dffae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dict_list_NSF_collab_patterns={}\n",
    "\n",
    "# for year_int in range(2010,2021):\n",
    "#     year=str(year_int)\n",
    "    \n",
    "#     # files_=glob.glob(path_data+'dict_NSF_careers_*')\n",
    "#     files_=glob.glob(path_data+'dict_NSF_careers_'+year+'*')\n",
    "#     #-----------------------------------------\n",
    "#     dict_careers={}\n",
    "#     for file in files_:\n",
    "#         with open(file, 'rb') as f:\n",
    "#             dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "#     dict_list_NSF_collab_patterns[year]=[]\n",
    "#     it_file=0\n",
    "#     #-----------------------------------------        \n",
    "#     t_ic = time.time();\n",
    "\n",
    "#     for key in dict_careers.keys():     \n",
    "#         it_file=it_file+1\n",
    "#         scientists_nsf=list(dict_careers[key].keys())\n",
    "#         # IT_=11\n",
    "#         # for it_sci in range(IT_,IT_+1):\n",
    "#         for it_sci in range(len(scientists_nsf)):\n",
    "#             sci=scientists_nsf[it_sci]\n",
    "\n",
    "#             x=json.loads(dict_careers[key][sci])\n",
    "#         #     print(sci,', works count=',len(x))\n",
    "#             if x!='NA':\n",
    "#                 for it_work in range(len(x)):\n",
    "#                     paper_=x[it_work]\n",
    "#                     affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "#                     author_pos_=[]\n",
    "#                     countries_=[]\n",
    "#                     author_names_=[]\n",
    "#                     store_unis=[]\n",
    "\n",
    "\n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "#                     for insti in affils_:\n",
    "#                         if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "#                             country=insti[0]['country_code'] ### I AM CONSIDERING ONLY THE FIRST AFFILIATION\n",
    "#                             uni=insti[0]['id']\n",
    "                            \n",
    "#                             countries_.append(country)\n",
    "#                             store_unis.append(uni)\n",
    "\n",
    "\n",
    "\n",
    "#                     for y in paper_['authorships']:\n",
    "#                         if 'display_name' in y['author'].keys():\n",
    "# #                             if y['author']['display_name']==sci:\n",
    "#                             if fuzz.token_sort_ratio(y['author']['display_name'],sci) >80:\n",
    "                                \n",
    "#                                 insti_main=y['institutions']\n",
    "                                \n",
    "#                     try:            \n",
    "#                         if len(insti_main)>0:\n",
    "#                             if 'country_code' in insti_main[0].keys():\n",
    "#                                 country_main=insti_main[0]['country_code']\n",
    "#                                 uni_main=insti_main[0]['id']\n",
    "#                             else:\n",
    "#                                 country_main=None\n",
    "#                                 uni_main=None\n",
    "#                         else:\n",
    "#                             country_main=None   \n",
    "#                             uni_main=None\n",
    "#                     except:\n",
    "#                         country_main=None   \n",
    "#                         uni_main=None\n",
    "#                     try:\n",
    "#                         del insti_main\n",
    "#                     except:\n",
    "#                         ''                    \n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "\n",
    "#                     dict_list_NSF_collab_patterns[year].append({'scientist':sci.replace(',',''),\n",
    "#                                                      'countries':countries_,\n",
    "#                                                      'team_size':len(paper_['authorships']),\n",
    "#                                                      'pub_year':paper_['publication_year'],\n",
    "#                                                      'country_awardee':country_main,\n",
    "#                                                     'uni_awardee':uni_main,\n",
    "#                                                                 'unis':store_unis\n",
    "#                                                                })\n",
    "                \n",
    "#         t_oc = time.time();\n",
    "#         progress='progress'+'--year--   '+str(year)+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "        \n",
    "#         print(progress,end='\\r')\n",
    "#         with open(path_codes+\"1_df_tracker.txt\", \"w\") as file_object:\n",
    "#             file_object.write(progress+'\\n')\n",
    "        \n",
    "#         with open(path_data+'dict_list_NSF_collab_patterns_'+year+'(nature physics).pkl', 'wb') as f:\n",
    "#             pickle.dump(dict_list_NSF_collab_patterns[year], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d046ca-a3b0-4e02-bc4a-d7b50a62e261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1252a1f9-365e-4be7-bcdf-9e9dba5470ac",
   "metadata": {},
   "source": [
    "## Only awardee country and affil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d2e32-56da-420e-a941-01bd9912165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2011--80---- 0.7619047619047619 695.33--estimated---0.254hourss\r"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_list_NSF_collab_patterns={}\n",
    "\n",
    "for year_int in range(2010,2021):\n",
    "    year=str(year_int)\n",
    "    \n",
    "    # files_=glob.glob(path_data+'dict_NSF_careers_*')\n",
    "    files_=glob.glob(path_data+'dict_NSF_careers_'+year+'*')\n",
    "    #-----------------------------------------\n",
    "    dict_careers={}\n",
    "    for file in files_:\n",
    "        with open(file, 'rb') as f:\n",
    "            dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "    dict_list_NSF_collab_patterns[year]=[]\n",
    "    it_file=0\n",
    "    #-----------------------------------------        \n",
    "    t_ic = time.time();\n",
    "\n",
    "    for key in dict_careers.keys():     \n",
    "        it_file=it_file+1\n",
    "        scientists_nsf=list(dict_careers[key].keys())\n",
    "        # IT_=11\n",
    "        # for it_sci in range(IT_,IT_+1):\n",
    "        for it_sci in range(len(scientists_nsf)):\n",
    "            sci=scientists_nsf[it_sci]\n",
    "\n",
    "            x=json.loads(dict_careers[key][sci])\n",
    "        #     print(sci,', works count=',len(x))\n",
    "            if x!='NA':\n",
    "                for it_work in range(len(x)):\n",
    "                    paper_=x[it_work]\n",
    "\n",
    "                    for y in paper_['authorships']:\n",
    "                        if 'display_name' in y['author'].keys():\n",
    "#                             if y['author']['display_name']==sci:\n",
    "                            if fuzz.token_sort_ratio(y['author']['display_name'],sci) >80:\n",
    "                                \n",
    "                                insti_main=y['institutions']\n",
    "                                \n",
    "                    try:            \n",
    "                        if len(insti_main)>0:\n",
    "                            if 'country_code' in insti_main[0].keys():\n",
    "                                country_main=insti_main[0]['country_code']\n",
    "                                uni_main=insti_main[0]['id']\n",
    "                            else:\n",
    "                                country_main=None\n",
    "                                uni_main=None\n",
    "                        else:\n",
    "                            country_main=None   \n",
    "                            uni_main=None\n",
    "                    except:\n",
    "                        country_main=None   \n",
    "                        uni_main=None\n",
    "                    try:\n",
    "                        del insti_main\n",
    "                    except:\n",
    "                        ''                    \n",
    "        #--------------------------------------------------------------------------------------------\n",
    "\n",
    "                    dict_list_NSF_collab_patterns[year].append({'scientist':sci.replace(',',''),\n",
    "                                                     'pub_year':paper_['publication_year'],\n",
    "                                                     'country_awardee':country_main,\n",
    "                                                    'uni_awardee':uni_main})\n",
    "                \n",
    "        t_oc = time.time();\n",
    "        progress='progress'+'--year--   '+str(year)+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "        \n",
    "        print(progress,end='\\r')\n",
    "        with open(path_codes+\"1_df_tracker.txt\", \"w\") as file_object:\n",
    "            file_object.write(progress+'\\n')\n",
    "        \n",
    "        with open(path_data+'dict_list_NSF_collab_patterns_(only awardee details)'+year+'(nature physics).pkl', 'wb') as f:\n",
    "            pickle.dump(dict_list_NSF_collab_patterns[year], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dc69e-7a50-4ed6-9576-b0ef971ca258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
