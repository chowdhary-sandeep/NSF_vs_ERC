{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fa2b98-6ee4-430d-98b6-592bf46f752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "my_file = open(\"all_country_codes.txt\", \"r\")\n",
    "all_country_codes = my_file.read()\n",
    "# print(all_country_codes)\n",
    "\n",
    "all_country_codes = all_country_codes.split(\"\\n\")[1:]\n",
    "all_country_codes = [x.split(\",\") for x in all_country_codes]\n",
    "all_country_codes\n",
    "\n",
    "\n",
    "my_file = open(\"eu_codes.txt\", \"r\")\n",
    "eu_codes = my_file.read()\n",
    "eu_codes = eu_codes.split(\"\\n\")\n",
    "eu_codes = [x.split(\"-\") for x in eu_codes]\n",
    "a=[]\n",
    "for x in eu_codes:\n",
    "    b=[]\n",
    "    for y in x:\n",
    "        b.append(y.strip())\n",
    "    a.append(b)\n",
    "eu_codes = [x[0:2] for x in eu_codes]\n",
    "eu_codes_only=[x[1].strip() for x in eu_codes]\n",
    "# eu_codes_only.append('GB')\n",
    "eu_codes_only=sorted(eu_codes_only)\n",
    "all_country_codes_only=[x[1].strip() for x in all_country_codes]\n",
    "\n",
    "# print(all_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4bf7c-dd7f-4155-9f63-e3eac838b6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e021bdac-0b83-47fc-a740-970569f0f585",
   "metadata": {},
   "source": [
    "# NSF : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00762987-9dce-47ce-8fe8-c5f444035b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2008--25---- 0.3333333333333333 1347.6--estimated---1.123hoursrs\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# dict_list_NSF_collab_patterns={}\n",
    "\n",
    "# for year_int in range(2008,2011):\n",
    "#     year=str(year_int)\n",
    "    \n",
    "#     # files_=glob.glob(path_data+'dict_NSF_careers_*')\n",
    "#     files_=glob.glob(path_data+'dict_NSF_careers_'+year+'*')\n",
    "#     #-----------------------------------------\n",
    "#     dict_careers={}\n",
    "#     for file in files_:\n",
    "#         with open(file, 'rb') as f:\n",
    "#             dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "#     dict_list_NSF_collab_patterns[year]=[]\n",
    "#     it_file=0\n",
    "#     #-----------------------------------------        \n",
    "#     t_ic = time.time();\n",
    "\n",
    "#     for key in dict_careers.keys():     \n",
    "#         it_file=it_file+1\n",
    "#         scientists_nsf=list(dict_careers[key].keys())\n",
    "#         # IT_=11\n",
    "#         # for it_sci in range(IT_,IT_+1):\n",
    "#         for it_sci in range(len(scientists_nsf)):\n",
    "#             sci=scientists_nsf[it_sci]\n",
    "\n",
    "#             x=json.loads(dict_careers[key][sci])\n",
    "#         #     print(sci,', works count=',len(x))\n",
    "#             if x!='NA':\n",
    "#                 for it_work in range(len(x)):\n",
    "#                     paper_=x[it_work]\n",
    "#                     affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "#                     author_pos_=[]\n",
    "#                     countries_=[]\n",
    "#                     author_names_=[]\n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "#                     for y in paper_['authorships']:\n",
    "#                         if 'display_name' in y['author'].keys():\n",
    "#                             author_names_.append(y['author']['display_name'])\n",
    "#                         else:\n",
    "#                             author_names_.append(-1)\n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "#                     for y in paper_['authorships']:\n",
    "#                         if 'author_position' in y.keys():\n",
    "#                             author_pos_.append(y['author_position'])\n",
    "#                         else:\n",
    "#                             author_pos_.append(-1)                        \n",
    "\n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "#                     for insti in affils_:\n",
    "#                         if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "#                             country=insti[0]['country_code'] ### I AM CONSIDERING ONLY THE FIRST AFFILIATION\n",
    "#                             countries_.append(country)\n",
    "#                         else:\n",
    "#                             countries_.append(-1)\n",
    "\n",
    "#                     for y in paper_['authorships']:\n",
    "#                         if 'display_name' in y['author'].keys():\n",
    "#                             if y['author']['display_name']==sci:\n",
    "#                                 insti_main=y['institutions']\n",
    "#                     try:            \n",
    "#                         if len(insti_main)>0:\n",
    "#                             if 'country_code' in insti_main[0].keys():\n",
    "#                                 country_main=insti_main[0]['country_code']\n",
    "#                             else:\n",
    "#                                 country_main=None\n",
    "#                         else:\n",
    "#                             country_main=None   \n",
    "#                     except:\n",
    "#                         country_main=None   \n",
    "#                     try:\n",
    "#                         del insti_main\n",
    "#                     except:\n",
    "#                         ''                    \n",
    "#         #--------------------------------------------------------------------------------------------\n",
    "\n",
    "#                     dict_list_NSF_collab_patterns[year].append({'scientist':sci.replace(',',''),\n",
    "#                                                      'countries':countries_,\n",
    "#                                                      'team_size':len(paper_['authorships']),\n",
    "#                                                      'pub_year':paper_['publication_year'],\n",
    "#                                                      'counts_by_year':paper_['counts_by_year'],\n",
    "#                                                      'country_awardee':country_main,\n",
    "#                                                      'open_access':paper_['open_access'],\n",
    "#                                                      'title':paper_['title'],\n",
    "#                                                      'concepts':paper_['concepts'],\n",
    "#                                                      'author_pos_':author_pos_,\n",
    "#                                                      'author_names_':author_names_\n",
    "#                                                     })\n",
    "                \n",
    "#         t_oc = time.time();\n",
    "#         progress='progress'+'--year--   '+str(year)+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "        \n",
    "#         print(progress,end='\\r')\n",
    "#         with open(path_codes+\"1_df_tracker.txt\", \"w\") as file_object:\n",
    "#             file_object.write(progress+'\\n')\n",
    "        \n",
    "#         with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'wb') as f:\n",
    "#             pickle.dump(dict_list_NSF_collab_patterns[year], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc34964-fd40-4cd4-8925-95434de737bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='/mnt/sdb1/sandeep/5. NSF vs ERC/data/dict_NSF_careers_2008_76.pkl'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8f8fe-e76b-4287-a4d9-99354209bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "# dict_list_NSF_collab_patterns={}\n",
    "\n",
    "# year='2011'\n",
    "# with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'rb') as f:\n",
    "#     dict_list_NSF_collab_patterns=pickle.load(f)   \n",
    "# dfs_NSF= pd.DataFrame(dict_list_NSF_collab_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864a7276-efd3-436e-8096-0ff78e7f2d5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-e52d7eafc7ea>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-e52d7eafc7ea>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    for country in list_top_countries:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# for year_int in range(2010,2021):\n",
    "\n",
    "#     year=str(year_int)\n",
    "#     print(year,end='\\r')\n",
    "#     with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'rb') as f:\n",
    "#         dict_list_NSF_collab_patterns=pickle.load(f)  \n",
    "#     dfs_NSF= pd.DataFrame(dict_list_NSF_collab_patterns)\n",
    "\n",
    "with open(path_data+'dfs_NSF_frq(nature physics).pkl', 'rb') as f:\n",
    "    dfs_NSF=pickle.load(f)          \n",
    "        \n",
    "dfs_NSF=dfs_NSF.sort_values(['scientist','pub_year'],ascending=True)\n",
    "dfs_NSF=dfs_NSF[dfs_NSF['scientist']!='- Robby']\n",
    "countries_temp=list(dfs_NSF['countries'])\n",
    "\n",
    "n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "dfs_NSF['identified_countries']=n_identified\n",
    "dfs_NSF['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "progress='progress'+'--year--   '+str(year)+'--n_US done'\n",
    "print(progress,end='\\r')\n",
    "with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "    file_object.write(progress+'\\n')\n",
    "\n",
    "list_top_countries=['AR', 'AU', 'BR', 'CA', 'CH', 'CL', 'CN', 'CO', 'GB', 'GE', 'IL', 'IN', 'JP', 'KR', 'MX', 'NO', 'PK', 'RS', 'RU', 'SG', 'TR', 'TW', 'ZA'] \n",
    "for country in list_top_countries:\n",
    "    dfs_NSF['n_'+country]=[np.sum(np.array(x)==country) for x in countries_temp]        \n",
    "\n",
    "progress='progress'+'--year--   '+str(year)+'--n_EU done'\n",
    "print(progress,end='\\r')\n",
    "with open(path_codes+\"2.nsf_tracker_top20.txt\", \"w\") as file_object:\n",
    "    file_object.write(progress+'\\n')\n",
    "\n",
    "#    dfs_NSF['subtract_from_n_US']=(dfs_NSF['country_awardee']=='US').astype('int')\n",
    "# dfs_NSF=dfs_NSF.drop(columns=['author_pos_','counts_by_year', 'country_awardee','open_access','title','concepts','author_names_'])\n",
    "\n",
    "progress='progress'+'--year--   '+str(year)+'--finished'\n",
    "print(progress,end='\\r')\n",
    "with open(path_codes+\"3.nsf_tracker.txt\", \"w\") as file_object:\n",
    "    file_object.write(progress+'\\n')\n",
    "with open(path_data+'dfs_NSF_main_top20'+str(year_int)+'.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs_NSF, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0280315a-5cad-44fe-a335-4f9c580668db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e311-5ca1-495a-a51f-ebb69bf8539e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0af839-9334-4a72-a5b3-dbf8e2c64cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d14f88-7dd7-46e6-a79f-93291b617eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-9cb42bdad9b7>:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dfs_NSF['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2010--n_US done\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdb1/sandeep/miniconda3/envs/sos/lib/python3.9/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2018--n_US done\r"
     ]
    }
   ],
   "source": [
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# for year_int in range(2010,2021):\n",
    "\n",
    "#     year=str(year_int)\n",
    "#     print(year,end='\\r')\n",
    "#     with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'rb') as f:\n",
    "#         dict_list_NSF_collab_patterns=pickle.load(f)   \n",
    "#     dfs_NSF= pd.DataFrame(dict_list_NSF_collab_patterns)\n",
    "#     dfs_NSF=dfs_NSF.sort_values(['scientist','pub_year'],ascending=True)\n",
    "#     dfs_NSF=dfs_NSF[dfs_NSF['scientist']!='- Robby']\n",
    "#     countries_temp=list(dfs_NSF['countries'])\n",
    "\n",
    "#     n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "#     dfs_NSF['identified_countries']=n_identified\n",
    "#     dfs_NSF['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "#     progress='progress'+'--year--   '+str(year)+'--n_US done'\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "    \n",
    "#     dfs_NSF['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "    \n",
    "#     progress='progress'+'--year--   '+str(year)+'--n_EU done'\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "    \n",
    "#     dfs_NSF['subtract_from_n_US']=(dfs_NSF['country_awardee']=='US').astype('int')\n",
    "#     dfs_NSF=dfs_NSF.drop(columns=['author_pos_','counts_by_year', 'country_awardee','open_access','title','concepts','author_names_'])\n",
    "\n",
    "#     progress='progress'+'--year--   '+str(year)+'--finished'\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "#     with open(path_data+'dfs_NSF_GB_included'+str(year_int)+'.pkl', 'wb') as f:\n",
    "#         pickle.dump(dfs_NSF, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939b3ee-756f-49b7-a8f1-5ebb7c4fb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_NSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab8363-ced1-49bc-91ca-4518c3838645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fe42eeb-11ab-46e9-b30f-870007878c5a",
   "metadata": {},
   "source": [
    "# ERC : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887367b-a81d-4baf-a8a4-4bacc38a5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list_ERC_collab_patterns=[]\n",
    "\n",
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "# #-----------------------------------------\n",
    "# dict_careers={}\n",
    "# for file in files_:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "\n",
    "# it_file=0\n",
    "# #-----------------------------------------        \n",
    "# t_ic = time.time();\n",
    "\n",
    "# for key in dict_careers.keys():     \n",
    "#     it_file=it_file+1\n",
    "#     scientists_nsf=list(dict_careers[key].keys())\n",
    "#     # IT_=11\n",
    "#     # for it_sci in range(IT_,IT_+1):\n",
    "#     for it_sci in range(len(scientists_nsf)):\n",
    "#         sci=scientists_nsf[it_sci]\n",
    "\n",
    "#         x=json.loads(dict_careers[key][sci])\n",
    "#     #     print(sci,', works count=',len(x))\n",
    "#         if x!='NA':\n",
    "#             for it_work in range(len(x)):\n",
    "#                 paper_=x[it_work]\n",
    "#         #         print(paper_.keys(),'\\n\\n')\n",
    "\n",
    "#         #         print(paper_['title'],'\\n')\n",
    "#         #         print('Team size=',len(paper_['authorships']))\n",
    "#         #         print('pub year=',(paper_['publication_year']))\n",
    "#         #         print('cited counts=',(paper_['counts_by_year']))\n",
    "\n",
    "#                 affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#         #         print(affils_,'\\n\\n')\n",
    "#                 countries_=[]\n",
    "\n",
    "#                 for insti in affils_:\n",
    "#                     if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "#                         country=insti[0]['country_code']\n",
    "#                         countries_.append(country)\n",
    "#         #         print([insti[0]['country_code'] for insti in affils_ if len(insti)>0])\n",
    "#         #         print(countries_)\n",
    "#                 for y in paper_['authorships']:\n",
    "#                     if 'display_name' in y['author'].keys():\n",
    "#                         if y['author']['display_name']==sci:\n",
    "#                             insti_main=y['institutions']\n",
    "#                 try:            \n",
    "#                     if len(insti_main)>0:\n",
    "#                         if 'country_code' in insti_main[0].keys():\n",
    "#                             country_main=insti_main[0]['country_code']\n",
    "#                         else:\n",
    "#                             country_main=None\n",
    "#                     else:\n",
    "#                         country_main=None   \n",
    "#                 except:\n",
    "#                     country_main=None   \n",
    "#                 try:\n",
    "#                     del insti_main\n",
    "#                 except:\n",
    "#                     ''                    \n",
    "#                 list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),'countries':countries_,'team_size':len(paper_['authorships']),'pub_year':paper_['publication_year'],'counts_by_year':paper_['counts_by_year'],'country_awardee':country_main})\n",
    "# #     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "#     t_oc = time.time();\n",
    "#     progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "\n",
    "# dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "# dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "# countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "# n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "# dfs_ERC['identified_countries']=n_identified\n",
    "# dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "# dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "# dfs_ERC['subtract_from_n_US']=(dfs_ERC['country_awardee']=='US').astype('int')\n",
    "\n",
    "# with open(path_data+'dfs_ERC.pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs_ERC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7235d8-23f2-4f52-b7c2-18d5bf78f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbd73c-5906-49e2-b3bd-40d3c7d57888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8f9e5-b172-48b2-9026-c558cfb515f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
