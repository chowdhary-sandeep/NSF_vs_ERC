{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94de6a0-e614-400d-bcff-d575c90d6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "my_file = open(\"all_country_codes.txt\", \"r\")\n",
    "all_country_codes = my_file.read()\n",
    "# print(all_country_codes)\n",
    "\n",
    "all_country_codes = all_country_codes.split(\"\\n\")[1:]\n",
    "all_country_codes = [x.split(\",\") for x in all_country_codes]\n",
    "all_country_codes\n",
    "\n",
    "\n",
    "my_file = open(\"eu_codes.txt\", \"r\")\n",
    "eu_codes = my_file.read()\n",
    "eu_codes = eu_codes.split(\"\\n\")\n",
    "eu_codes = [x.split(\"-\") for x in eu_codes]\n",
    "a=[]\n",
    "for x in eu_codes:\n",
    "    b=[]\n",
    "    for y in x:\n",
    "        b.append(y.strip())\n",
    "    a.append(b)\n",
    "eu_codes = [x[0:2] for x in eu_codes]\n",
    "eu_codes_only=[x[1].strip() for x in eu_codes]\n",
    "eu_codes_only.append('GB')\n",
    "eu_codes_only=sorted(eu_codes_only)\n",
    "all_country_codes_only=[x[1].strip() for x in all_country_codes]\n",
    "\n",
    "# print(all_country_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab164fa-0f61-4a7c-92c7-b6eb25129b56",
   "metadata": {},
   "source": [
    "# ERC: collecting names of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c5ee0d-ee26-477f-9cd3-def982775d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "#-----------------------------------------\n",
    "dict_careers={}\n",
    "for file in files_:\n",
    "    with open(file, 'rb') as f:\n",
    "        dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9cd377-95b8-4a44-9d51-485d5b110e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--119---- 1.0 1163.29--estimated---0.323hoursed---0.322hours\r"
     ]
    }
   ],
   "source": [
    "list_ERC_collab_patterns=[]\n",
    "\n",
    "it_file=0\n",
    "#-----------------------------------------        \n",
    "t_ic = time.time();\n",
    "\n",
    "for key in dict_careers.keys():     \n",
    "    it_file=it_file+1\n",
    "    scientists_nsf=list(dict_careers[key].keys())\n",
    "    # IT_=11\n",
    "    # for it_sci in range(IT_,IT_+1):\n",
    "    for it_sci in range(1,len(scientists_nsf)):\n",
    "        sci=scientists_nsf[it_sci]\n",
    "#         print(sci.replace(',',''),'\\n')\n",
    "\n",
    "        x=json.loads(dict_careers[key][sci])\n",
    "    #     print(sci,', works count=',len(x))\n",
    "        if x!='NA':\n",
    "            for it_work in range(len(x)):\n",
    "                paper_=x[it_work]\n",
    "#                 print(paper_.keys(),'\\n\\n')\n",
    "#                 print(paper_['title'],'\\n')\n",
    "#                 print(paper_['authorships'])\n",
    "\n",
    "                affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                author_pos_=[]\n",
    "                countries_=[]\n",
    "                author_names_=[]\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        author_names_.append(y['author']['display_name'])\n",
    "                    else:\n",
    "                        author_names_.append(-1)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'author_position' in y.keys():\n",
    "                        author_pos_.append(y['author_position'])\n",
    "                    else:\n",
    "                        author_pos_.append(-1)                        \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for insti in affils_:\n",
    "                    if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "                        country=insti[0]['country_code'] ### I AM CONSIDERING ONLY THE FIRST AFFILIATION\n",
    "                        countries_.append(country)\n",
    "                    else:\n",
    "                        countries_.append(-1)\n",
    "\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        if y['author']['display_name']==sci:\n",
    "                            insti_main=y['institutions']\n",
    "                try:            \n",
    "                    if len(insti_main)>0:\n",
    "                        if 'country_code' in insti_main[0].keys():\n",
    "                            country_main=insti_main[0]['country_code']\n",
    "                        else:\n",
    "                            country_main=None\n",
    "                    else:\n",
    "                        country_main=None   \n",
    "                except:\n",
    "                    country_main=None   \n",
    "                try:\n",
    "                    del insti_main\n",
    "                except:\n",
    "                    ''                    \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "                list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),\n",
    "                                                 'countries':countries_,\n",
    "                                                 'team_size':len(paper_['authorships']),\n",
    "                                                 'pub_year':paper_['publication_year'],\n",
    "                                                 'counts_by_year':paper_['counts_by_year'],\n",
    "                                                 'country_awardee':country_main,\n",
    "                                                 'open_access':paper_['open_access'],\n",
    "                                                 'title':paper_['title'],\n",
    "                                                 'concepts':paper_['concepts'],\n",
    "                                                 'author_pos_':author_pos_,\n",
    "                                                 'author_names_':author_names_\n",
    "                                                })\n",
    "                \n",
    "\n",
    "#     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "    \n",
    "    t_oc = time.time();\n",
    "    progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef040b9a-8517-4c04-9c7e-38f597f23a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data+'list_ERC_collab_patterns(frequency of countries).pkl', 'wb') as f:\n",
    "    pickle.dump(list_ERC_collab_patterns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4768a-c5c1-4859-b60e-00318511f8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d8bd093e0270>:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
      "/mnt/sdb1/sandeep/miniconda3/envs/sos/lib/python3.9/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "dfs_ERC['identified_countries']=n_identified\n",
    "dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "for country in ['IN','CN','JP','BR']:\n",
    "    dfs_ERC['n_'+country]=[np.sum(np.array(x)==country) for x in countries_temp]        \n",
    "dfs_ERC=dfs_ERC.drop(columns=['author_pos_','counts_by_year', 'country_awardee','open_access','title','concepts','author_names_'])\n",
    "    \n",
    "with open(path_data+'dfs_ERC_china_etc.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs_ERC, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c750bc7f-6ccb-4545-8ba0-9e5cdf3ebde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'       \n",
    "\n",
    "# with open(path_data+'dfs_ERC_with_collab_names.pkl', 'rb') as f:\n",
    "#     dfs_ERC=pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c19ee7-4eab-43ee-9a31-d146798ee089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get career staring year for each author.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f1d8d-5dfe-489c-8041-761a34ae05bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
