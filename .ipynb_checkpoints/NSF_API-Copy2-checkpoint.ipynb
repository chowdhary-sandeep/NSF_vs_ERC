{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f31818-e13b-47f9-8b6b-05f8d2bd607a",
   "metadata": {},
   "source": [
    "## creating dict_careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bf56ad-33f6-49c8-bed7-893e4d4a9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = np.arange(1975,2023)\n",
    "# from main_career import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1614c13b-14ab-4b12-86e0-83037f086670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILES ARE MISNAMED (ERC instead of NSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48970cad-899c-419b-bb1f-ccc2c9c286ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "\n",
    "import pickle\n",
    "from get_career import *\n",
    "\n",
    "def main(year):\n",
    "    year=str(year);\n",
    "\n",
    "\n",
    "    path_career='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "    #----------------\n",
    "    dict_careers={}\n",
    "    with open(path_career+'NSF_names_'+str(year)+'.pkl', 'rb') as f:\n",
    "        names_=pickle.load(f)    \n",
    "    t_ic = time.time();\n",
    "    path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "    \n",
    "    for it in range(-1+1,len(names_)):\n",
    "        auth_name_to_search=names_[it]\n",
    "        career_=get_career_from_name(auth_name_to_search.replace(',',''));\n",
    "        dict_careers[auth_name_to_search] = json.dumps(career_)\n",
    "#         if it%10==0:\n",
    "        print(it,len(names_),end='\\r')\n",
    "        t_oc = time.time();\n",
    "        progress=year+'   '+str(it)+ '---- '+str((it+1)/len(names_))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/((it+1)/len(names_))/3600,3))+'hours'\n",
    "        print(progress,end='\\r')\n",
    "        with open(path_codes+\"0_track_\"+year+\".txt\", \"w\") as file_object:\n",
    "            file_object.write(progress+'\\n')\n",
    "\n",
    "        if (it%100==0) and it>0:\n",
    "            num_file=round((it+1)/100)\n",
    "            path_career='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "            with open(path_career+'dict_NSF_careers_'+year+'_'+str(num_file)+'.pkl', 'wb') as f:\n",
    "                pickle.dump(dict_careers, f)\n",
    "            dict_careers={} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c843d-596a-4e17-a6c1-0b9ac60d4c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009   405---- 0.029839776569160665 1366.72--estimated---12.723hours\r"
     ]
    }
   ],
   "source": [
    "main(2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359185a5-e814-4456-aba8-1005dd44b3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc44c4-5d01-409c-8059-97612c41ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with Pool(2) as pool: #  parallel jobs\n",
    "#         results = pool.map(main, np.arange(2010,2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd626436-b8a7-4a88-bef8-bc8557eb215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with Pool(5) as pool: #  parallel jobs\n",
    "#         results = pool.map(main, np.arange(2015,2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fd888-158e-4048-931b-22b1dbf1c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with Pool(5) as pool: #  parallel jobs\n",
    "#         results = pool.map(main, np.arange(1990,2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a0f1c-f260-4767-9da3-701e464755d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with Pool(5) as pool: #  parallel jobs\n",
    "#         results = pool.map(main, np.arange(1975,1990))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fbc90-0e13-4840-abb1-483b65bcfb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbb8c1-37b5-4aa1-b43d-3703b729928e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
