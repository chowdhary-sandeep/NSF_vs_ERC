{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fa2b98-6ee4-430d-98b6-592bf46f752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "my_file = open(\"all_country_codes.txt\", \"r\")\n",
    "all_country_codes = my_file.read()\n",
    "# print(all_country_codes)\n",
    "\n",
    "all_country_codes = all_country_codes.split(\"\\n\")[1:]\n",
    "all_country_codes = [x.split(\",\") for x in all_country_codes]\n",
    "all_country_codes\n",
    "\n",
    "\n",
    "my_file = open(\"eu_codes.txt\", \"r\")\n",
    "eu_codes = my_file.read()\n",
    "eu_codes = eu_codes.split(\"\\n\")\n",
    "eu_codes = [x.split(\"-\") for x in eu_codes]\n",
    "a=[]\n",
    "for x in eu_codes:\n",
    "    b=[]\n",
    "    for y in x:\n",
    "        b.append(y.strip())\n",
    "    a.append(b)\n",
    "eu_codes = [x[0:2] for x in eu_codes]\n",
    "eu_codes_only=[x[1].strip() for x in eu_codes]\n",
    "eu_codes_only.append('GB')\n",
    "eu_codes_only=sorted(eu_codes_only)\n",
    "all_country_codes_only=[x[1].strip() for x in all_country_codes]\n",
    "\n",
    "# print(all_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4bf7c-dd7f-4155-9f63-e3eac838b6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e021bdac-0b83-47fc-a740-970569f0f585",
   "metadata": {},
   "source": [
    "# NSF : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00762987-9dce-47ce-8fe8-c5f444035b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2008--1---- 0.013333333333333334 45.24--estimated---0.942hours\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3142f76b1b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0minsti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffils_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'country_code'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minsti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                             \u001b[0mcountry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minsti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m### I AM CONSIDERING ONLY THE FIRST AFFILIATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                             \u001b[0mcountries_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dict_list_NSF_collab_patterns={}\n",
    "\n",
    "for year_int in range(2008,2011):\n",
    "    year=str(year_int)\n",
    "    \n",
    "    # files_=glob.glob(path_data+'dict_NSF_careers_*')\n",
    "    files_=glob.glob(path_data+'dict_NSF_careers_'+year+'*')\n",
    "    #-----------------------------------------\n",
    "    dict_careers={}\n",
    "    for file in files_:\n",
    "        with open(file, 'rb') as f:\n",
    "            dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "    dict_list_NSF_collab_patterns[year]=[]\n",
    "    it_file=0\n",
    "    #-----------------------------------------        \n",
    "    t_ic = time.time();\n",
    "\n",
    "    for key in dict_careers.keys():     \n",
    "        it_file=it_file+1\n",
    "        scientists_nsf=list(dict_careers[key].keys())\n",
    "        # IT_=11\n",
    "        # for it_sci in range(IT_,IT_+1):\n",
    "        for it_sci in range(len(scientists_nsf)):\n",
    "            sci=scientists_nsf[it_sci]\n",
    "\n",
    "            x=json.loads(dict_careers[key][sci])\n",
    "        #     print(sci,', works count=',len(x))\n",
    "            if x!='NA':\n",
    "                for it_work in range(len(x)):\n",
    "                    paper_=x[it_work]\n",
    "                    affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "        #--------------------------------------------------------------------------------------------\n",
    "                    author_pos_=[]\n",
    "                    countries_=[]\n",
    "                    author_names_=[]\n",
    "        #--------------------------------------------------------------------------------------------\n",
    "                    for y in paper_['authorships']:\n",
    "                        if 'display_name' in y['author'].keys():\n",
    "                            author_names_.append(y['author']['display_name'])\n",
    "                        else:\n",
    "                            author_names_.append(-1)\n",
    "        #--------------------------------------------------------------------------------------------\n",
    "                    for y in paper_['authorships']:\n",
    "                        if 'author_position' in y.keys():\n",
    "                            author_pos_.append(y['author_position'])\n",
    "                        else:\n",
    "                            author_pos_.append(-1)                        \n",
    "\n",
    "        #--------------------------------------------------------------------------------------------\n",
    "                    for insti in affils_:\n",
    "                        if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "                            country=insti[0]['country_code'] ### I AM CONSIDERING ONLY THE FIRST AFFILIATION\n",
    "                            countries_.append(country)\n",
    "                        else:\n",
    "                            countries_.append(-1)\n",
    "\n",
    "                    for y in paper_['authorships']:\n",
    "                        if 'display_name' in y['author'].keys():\n",
    "                            if y['author']['display_name']==sci:\n",
    "                                insti_main=y['institutions']\n",
    "                    try:            \n",
    "                        if len(insti_main)>0:\n",
    "                            if 'country_code' in insti_main[0].keys():\n",
    "                                country_main=insti_main[0]['country_code']\n",
    "                            else:\n",
    "                                country_main=None\n",
    "                        else:\n",
    "                            country_main=None   \n",
    "                    except:\n",
    "                        country_main=None   \n",
    "                    try:\n",
    "                        del insti_main\n",
    "                    except:\n",
    "                        ''                    \n",
    "        #--------------------------------------------------------------------------------------------\n",
    "\n",
    "                    dict_list_NSF_collab_patterns[year].append({'scientist':sci.replace(',',''),\n",
    "                                                     'countries':countries_,\n",
    "                                                     'team_size':len(paper_['authorships']),\n",
    "                                                     'pub_year':paper_['publication_year'],\n",
    "                                                     'counts_by_year':paper_['counts_by_year'],\n",
    "                                                     'country_awardee':country_main,\n",
    "                                                     'open_access':paper_['open_access'],\n",
    "                                                     'title':paper_['title'],\n",
    "                                                     'concepts':paper_['concepts'],\n",
    "                                                     'author_pos_':author_pos_,\n",
    "                                                     'author_names_':author_names_\n",
    "                                                    })\n",
    "                \n",
    "        t_oc = time.time();\n",
    "        progress='progress'+'--year--   '+str(year)+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "        \n",
    "        print(progress,end='\\r')\n",
    "        with open(path_codes+\"1_df_tracker.txt\", \"w\") as file_object:\n",
    "            file_object.write(progress+'\\n')\n",
    "        \n",
    "        with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_list_NSF_collab_patterns[year], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc34964-fd40-4cd4-8925-95434de737bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='/mnt/sdb1/sandeep/5. NSF vs ERC/data/dict_NSF_careers_2008_76.pkl'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8f8fe-e76b-4287-a4d9-99354209bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "# dict_list_NSF_collab_patterns={}\n",
    "\n",
    "# year='2011'\n",
    "# with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'rb') as f:\n",
    "#     dict_list_NSF_collab_patterns=pickle.load(f)   \n",
    "# dfs_NSF= pd.DataFrame(dict_list_NSF_collab_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a7276-efd3-436e-8096-0ff78e7f2d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280315a-5cad-44fe-a335-4f9c580668db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e311-5ca1-495a-a51f-ebb69bf8539e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0af839-9334-4a72-a5b3-dbf8e2c64cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d14f88-7dd7-46e6-a79f-93291b617eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\r"
     ]
    }
   ],
   "source": [
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "for year_int in range(2010,2021):\n",
    "\n",
    "    year=str(year_int)\n",
    "    print(year,end='\\r')\n",
    "    with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'rb') as f:\n",
    "        dict_list_NSF_collab_patterns=pickle.load(f)   \n",
    "    dfs_NSF= pd.DataFrame(dict_list_NSF_collab_patterns)\n",
    "    dfs_NSF=dfs_NSF.sort_values(['scientist','pub_year'],ascending=True)\n",
    "    dfs_NSF=dfs_NSF[dfs_NSF['scientist']!='- Robby']\n",
    "    countries_temp=list(dfs_NSF['countries'])\n",
    "\n",
    "    n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "    dfs_NSF['identified_countries']=n_identified\n",
    "    dfs_NSF['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "    progress='progress'+'--year--   '+str(year)+'--n_US done'\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "    \n",
    "    dfs_NSF['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "    \n",
    "    progress='progress'+'--year--   '+str(year)+'--n_EU done'\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "    \n",
    "    dfs_NSF['subtract_from_n_US']=(dfs_NSF['country_awardee']=='US').astype('int')\n",
    "    dfs_NSF=dfs_NSF.drop(columns=['author_pos_','counts_by_year', 'country_awardee','open_access','title','concepts','author_names_'])\n",
    "\n",
    "    progress='progress'+'--year--   '+str(year)+'--finished'\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "    with open(path_data+'dfs_NSF_GB_included'+str(year_int)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(dfs_NSF, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939b3ee-756f-49b7-a8f1-5ebb7c4fb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_NSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ab8363-ced1-49bc-91ca-4518c3838645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scientist</th>\n",
       "      <th>countries</th>\n",
       "      <th>team_size</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>counts_by_year</th>\n",
       "      <th>country_awardee</th>\n",
       "      <th>open_access</th>\n",
       "      <th>title</th>\n",
       "      <th>concepts</th>\n",
       "      <th>author_pos_</th>\n",
       "      <th>author_names_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Radu Laza</td>\n",
       "      <td>[US, US, JP]</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'year': 2021, 'cited_by_count': 1}]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'green', 'oa_url'...</td>\n",
       "      <td>Hodge theory of degenerations, (I): consequenc...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C124681953', 'wi...</td>\n",
       "      <td>[first, middle, last]</td>\n",
       "      <td>[Matt Kerr, Radu Laza, Morihiko Saito]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radu Laza</td>\n",
       "      <td>[US, DE]</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'year': 2021, 'cited_by_count': 2}]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'hybrid', 'oa_url...</td>\n",
       "      <td>Automorphisms and periods of cubic fourfolds</td>\n",
       "      <td>[{'id': 'https://openalex.org/C118712358', 'wi...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Radu Laza, Zhiwei Zheng]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radu Laza</td>\n",
       "      <td>[US, US, US, US]</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'year': 2021, 'cited_by_count': 1}]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>The LLV decomposition of hyper-Kähler cohomolo...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C33923547', 'wik...</td>\n",
       "      <td>[first, middle, middle, last]</td>\n",
       "      <td>[Mark Green, Yoon-Joo Kim, Radu Laza, Colleen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radu Laza</td>\n",
       "      <td>[US, IT]</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'year': 2021, 'cited_by_count': 4}, {'year':...</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'bronze', 'oa_url...</td>\n",
       "      <td>GIT versus Baily-Borel compactification for K3...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C33923547', 'wik...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Radu Laza, Kieran G. O'Grady]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radu Laza</td>\n",
       "      <td>[US]</td>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'year': 2021, 'cited_by_count': 1}]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'hybrid', 'oa_url...</td>\n",
       "      <td>Maximally algebraic potentially irrational cub...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C11413529', 'wik...</td>\n",
       "      <td>[first]</td>\n",
       "      <td>[Radu Laza]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386300</th>\n",
       "      <td>Dariush Divsalar</td>\n",
       "      <td>[US, US]</td>\n",
       "      <td>2</td>\n",
       "      <td>1982</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': None, 'oa_url': N...</td>\n",
       "      <td>A coupled phase-locked loops system for carrie...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C12707504', 'wik...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Dariush Divsalar, J. H. Yuen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386301</th>\n",
       "      <td>Dariush Divsalar</td>\n",
       "      <td>[US, US]</td>\n",
       "      <td>2</td>\n",
       "      <td>1982</td>\n",
       "      <td>[{'year': 2018, 'cited_by_count': 1}]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': False, 'oa_status': 'closed', 'oa_ur...</td>\n",
       "      <td>The Power Spectral Density of Digital Modulati...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C123079801', 'wi...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Dariush Divsalar, Marvin K. Simon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386302</th>\n",
       "      <td>Dariush Divsalar</td>\n",
       "      <td>[US, US]</td>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': None, 'oa_url': N...</td>\n",
       "      <td>Performance of quadrature overlapped raised-co...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C195251586', 'wi...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Dariush Divsalar, Marvin K. Simon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386303</th>\n",
       "      <td>Dariush Divsalar</td>\n",
       "      <td>[US, US]</td>\n",
       "      <td>2</td>\n",
       "      <td>1980</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': 'green', 'oa_url'...</td>\n",
       "      <td>Spectral Characteristics of Convolutionally Co...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C157899210', 'wi...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Dariush Divsalar, Marvin K. Simon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386304</th>\n",
       "      <td>Dariush Divsalar</td>\n",
       "      <td>[US, US]</td>\n",
       "      <td>2</td>\n",
       "      <td>1979</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>{'is_oa': True, 'oa_status': None, 'oa_url': N...</td>\n",
       "      <td>Performance of mismatched Viterbi receiver on ...</td>\n",
       "      <td>[{'id': 'https://openalex.org/C41008148', 'wik...</td>\n",
       "      <td>[first, last]</td>\n",
       "      <td>[Dariush Divsalar, J. K. Omura]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1386305 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                scientist         countries  team_size  pub_year  \\\n",
       "0               Radu Laza      [US, US, JP]          3      2021   \n",
       "1               Radu Laza          [US, DE]          2      2021   \n",
       "2               Radu Laza  [US, US, US, US]          4      2021   \n",
       "3               Radu Laza          [US, IT]          2      2021   \n",
       "4               Radu Laza              [US]          1      2021   \n",
       "...                   ...               ...        ...       ...   \n",
       "1386300  Dariush Divsalar          [US, US]          2      1982   \n",
       "1386301  Dariush Divsalar          [US, US]          2      1982   \n",
       "1386302  Dariush Divsalar          [US, US]          2      1981   \n",
       "1386303  Dariush Divsalar          [US, US]          2      1980   \n",
       "1386304  Dariush Divsalar          [US, US]          2      1979   \n",
       "\n",
       "                                            counts_by_year country_awardee  \\\n",
       "0                    [{'year': 2021, 'cited_by_count': 1}]              US   \n",
       "1                    [{'year': 2021, 'cited_by_count': 2}]              US   \n",
       "2                    [{'year': 2021, 'cited_by_count': 1}]              US   \n",
       "3        [{'year': 2021, 'cited_by_count': 4}, {'year':...              US   \n",
       "4                    [{'year': 2021, 'cited_by_count': 1}]              US   \n",
       "...                                                    ...             ...   \n",
       "1386300                                                 []              US   \n",
       "1386301              [{'year': 2018, 'cited_by_count': 1}]              US   \n",
       "1386302                                                 []              US   \n",
       "1386303                                                 []              US   \n",
       "1386304                                                 []              US   \n",
       "\n",
       "                                               open_access  \\\n",
       "0        {'is_oa': True, 'oa_status': 'green', 'oa_url'...   \n",
       "1        {'is_oa': True, 'oa_status': 'hybrid', 'oa_url...   \n",
       "2        {'is_oa': False, 'oa_status': 'closed', 'oa_ur...   \n",
       "3        {'is_oa': True, 'oa_status': 'bronze', 'oa_url...   \n",
       "4        {'is_oa': True, 'oa_status': 'hybrid', 'oa_url...   \n",
       "...                                                    ...   \n",
       "1386300  {'is_oa': True, 'oa_status': None, 'oa_url': N...   \n",
       "1386301  {'is_oa': False, 'oa_status': 'closed', 'oa_ur...   \n",
       "1386302  {'is_oa': True, 'oa_status': None, 'oa_url': N...   \n",
       "1386303  {'is_oa': True, 'oa_status': 'green', 'oa_url'...   \n",
       "1386304  {'is_oa': True, 'oa_status': None, 'oa_url': N...   \n",
       "\n",
       "                                                     title  \\\n",
       "0        Hodge theory of degenerations, (I): consequenc...   \n",
       "1             Automorphisms and periods of cubic fourfolds   \n",
       "2        The LLV decomposition of hyper-Kähler cohomolo...   \n",
       "3        GIT versus Baily-Borel compactification for K3...   \n",
       "4        Maximally algebraic potentially irrational cub...   \n",
       "...                                                    ...   \n",
       "1386300  A coupled phase-locked loops system for carrie...   \n",
       "1386301  The Power Spectral Density of Digital Modulati...   \n",
       "1386302  Performance of quadrature overlapped raised-co...   \n",
       "1386303  Spectral Characteristics of Convolutionally Co...   \n",
       "1386304  Performance of mismatched Viterbi receiver on ...   \n",
       "\n",
       "                                                  concepts  \\\n",
       "0        [{'id': 'https://openalex.org/C124681953', 'wi...   \n",
       "1        [{'id': 'https://openalex.org/C118712358', 'wi...   \n",
       "2        [{'id': 'https://openalex.org/C33923547', 'wik...   \n",
       "3        [{'id': 'https://openalex.org/C33923547', 'wik...   \n",
       "4        [{'id': 'https://openalex.org/C11413529', 'wik...   \n",
       "...                                                    ...   \n",
       "1386300  [{'id': 'https://openalex.org/C12707504', 'wik...   \n",
       "1386301  [{'id': 'https://openalex.org/C123079801', 'wi...   \n",
       "1386302  [{'id': 'https://openalex.org/C195251586', 'wi...   \n",
       "1386303  [{'id': 'https://openalex.org/C157899210', 'wi...   \n",
       "1386304  [{'id': 'https://openalex.org/C41008148', 'wik...   \n",
       "\n",
       "                           author_pos_  \\\n",
       "0                [first, middle, last]   \n",
       "1                        [first, last]   \n",
       "2        [first, middle, middle, last]   \n",
       "3                        [first, last]   \n",
       "4                              [first]   \n",
       "...                                ...   \n",
       "1386300                  [first, last]   \n",
       "1386301                  [first, last]   \n",
       "1386302                  [first, last]   \n",
       "1386303                  [first, last]   \n",
       "1386304                  [first, last]   \n",
       "\n",
       "                                             author_names_  \n",
       "0                   [Matt Kerr, Radu Laza, Morihiko Saito]  \n",
       "1                                [Radu Laza, Zhiwei Zheng]  \n",
       "2        [Mark Green, Yoon-Joo Kim, Radu Laza, Colleen ...  \n",
       "3                           [Radu Laza, Kieran G. O'Grady]  \n",
       "4                                              [Radu Laza]  \n",
       "...                                                    ...  \n",
       "1386300                     [Dariush Divsalar, J. H. Yuen]  \n",
       "1386301                [Dariush Divsalar, Marvin K. Simon]  \n",
       "1386302                [Dariush Divsalar, Marvin K. Simon]  \n",
       "1386303                [Dariush Divsalar, Marvin K. Simon]  \n",
       "1386304                    [Dariush Divsalar, J. K. Omura]  \n",
       "\n",
       "[1386305 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_NSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe42eeb-11ab-46e9-b30f-870007878c5a",
   "metadata": {},
   "source": [
    "# ERC : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887367b-a81d-4baf-a8a4-4bacc38a5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list_ERC_collab_patterns=[]\n",
    "\n",
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "# #-----------------------------------------\n",
    "# dict_careers={}\n",
    "# for file in files_:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "\n",
    "# it_file=0\n",
    "# #-----------------------------------------        \n",
    "# t_ic = time.time();\n",
    "\n",
    "# for key in dict_careers.keys():     \n",
    "#     it_file=it_file+1\n",
    "#     scientists_nsf=list(dict_careers[key].keys())\n",
    "#     # IT_=11\n",
    "#     # for it_sci in range(IT_,IT_+1):\n",
    "#     for it_sci in range(len(scientists_nsf)):\n",
    "#         sci=scientists_nsf[it_sci]\n",
    "\n",
    "#         x=json.loads(dict_careers[key][sci])\n",
    "#     #     print(sci,', works count=',len(x))\n",
    "#         if x!='NA':\n",
    "#             for it_work in range(len(x)):\n",
    "#                 paper_=x[it_work]\n",
    "#         #         print(paper_.keys(),'\\n\\n')\n",
    "\n",
    "#         #         print(paper_['title'],'\\n')\n",
    "#         #         print('Team size=',len(paper_['authorships']))\n",
    "#         #         print('pub year=',(paper_['publication_year']))\n",
    "#         #         print('cited counts=',(paper_['counts_by_year']))\n",
    "\n",
    "#                 affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#         #         print(affils_,'\\n\\n')\n",
    "#                 countries_=[]\n",
    "\n",
    "#                 for insti in affils_:\n",
    "#                     if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "#                         country=insti[0]['country_code']\n",
    "#                         countries_.append(country)\n",
    "#         #         print([insti[0]['country_code'] for insti in affils_ if len(insti)>0])\n",
    "#         #         print(countries_)\n",
    "#                 for y in paper_['authorships']:\n",
    "#                     if 'display_name' in y['author'].keys():\n",
    "#                         if y['author']['display_name']==sci:\n",
    "#                             insti_main=y['institutions']\n",
    "#                 try:            \n",
    "#                     if len(insti_main)>0:\n",
    "#                         if 'country_code' in insti_main[0].keys():\n",
    "#                             country_main=insti_main[0]['country_code']\n",
    "#                         else:\n",
    "#                             country_main=None\n",
    "#                     else:\n",
    "#                         country_main=None   \n",
    "#                 except:\n",
    "#                     country_main=None   \n",
    "#                 try:\n",
    "#                     del insti_main\n",
    "#                 except:\n",
    "#                     ''                    \n",
    "#                 list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),'countries':countries_,'team_size':len(paper_['authorships']),'pub_year':paper_['publication_year'],'counts_by_year':paper_['counts_by_year'],'country_awardee':country_main})\n",
    "# #     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "#     t_oc = time.time();\n",
    "#     progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "\n",
    "# dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "# dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "# countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "# n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "# dfs_ERC['identified_countries']=n_identified\n",
    "# dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "# dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "# dfs_ERC['subtract_from_n_US']=(dfs_ERC['country_awardee']=='US').astype('int')\n",
    "\n",
    "# with open(path_data+'dfs_ERC.pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs_ERC, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7235d8-23f2-4f52-b7c2-18d5bf78f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbd73c-5906-49e2-b3bd-40d3c7d57888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b8f9e5-b172-48b2-9026-c558cfb515f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acb9d61d-7c6e-447f-8311-3dfbab563511",
   "metadata": {},
   "source": [
    "# ERC: collecting names of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46e4cd-cab2-41f5-8cb3-d1b6d81967e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "#-----------------------------------------\n",
    "dict_careers={}\n",
    "for file in files_:\n",
    "    with open(file, 'rb') as f:\n",
    "        dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "996c9f5c-3445-4923-8fbe-ae4bc03531ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--119---- 1.0 1219.44--estimated---0.339hoursed---0.341hours\r"
     ]
    }
   ],
   "source": [
    "list_ERC_collab_patterns=[]\n",
    "\n",
    "it_file=0\n",
    "#-----------------------------------------        \n",
    "t_ic = time.time();\n",
    "\n",
    "for key in dict_careers.keys():     \n",
    "    it_file=it_file+1\n",
    "    scientists_nsf=list(dict_careers[key].keys())\n",
    "    # IT_=11\n",
    "    # for it_sci in range(IT_,IT_+1):\n",
    "    for it_sci in range(1,len(scientists_nsf)):\n",
    "        sci=scientists_nsf[it_sci]\n",
    "#         print(sci.replace(',',''),'\\n')\n",
    "\n",
    "        x=json.loads(dict_careers[key][sci])\n",
    "    #     print(sci,', works count=',len(x))\n",
    "        if x!='NA':\n",
    "            for it_work in range(len(x)):\n",
    "                paper_=x[it_work]\n",
    "#                 print(paper_.keys(),'\\n\\n')\n",
    "#                 print(paper_['title'],'\\n')\n",
    "#                 print(paper_['authorships'])\n",
    "\n",
    "                affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                author_pos_=[]\n",
    "                countries_=[]\n",
    "                author_names_=[]\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        author_names_.append(y['author']['display_name'])\n",
    "                    else:\n",
    "                        author_names_.append(-1)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'author_position' in y.keys():\n",
    "                        author_pos_.append(y['author_position'])\n",
    "                    else:\n",
    "                        author_pos_.append(-1)                        \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for insti in affils_:\n",
    "                    if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "                        country=insti[0]['country_code'] ### I AM CONSIDERING ONLY THE FIRST AFFILIATION\n",
    "                        countries_.append(country)\n",
    "                    else:\n",
    "                        countries_.append(-1)\n",
    "\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        if y['author']['display_name']==sci:\n",
    "                            insti_main=y['institutions']\n",
    "                try:            \n",
    "                    if len(insti_main)>0:\n",
    "                        if 'country_code' in insti_main[0].keys():\n",
    "                            country_main=insti_main[0]['country_code']\n",
    "                        else:\n",
    "                            country_main=None\n",
    "                    else:\n",
    "                        country_main=None   \n",
    "                except:\n",
    "                    country_main=None   \n",
    "                try:\n",
    "                    del insti_main\n",
    "                except:\n",
    "                    ''                    \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "                list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),\n",
    "                                                 'countries':countries_,\n",
    "                                                 'team_size':len(paper_['authorships']),\n",
    "                                                 'pub_year':paper_['publication_year'],\n",
    "                                                 'counts_by_year':paper_['counts_by_year'],\n",
    "                                                 'country_awardee':country_main,\n",
    "                                                 'open_access':paper_['open_access'],\n",
    "                                                 'title':paper_['title'],\n",
    "                                                 'concepts':paper_['concepts'],\n",
    "                                                 'author_pos_':author_pos_,\n",
    "                                                 'author_names_':author_names_\n",
    "                                                })\n",
    "                \n",
    "\n",
    "#     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "    \n",
    "    t_oc = time.time();\n",
    "    progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414fdc03-f234-480f-84bd-2d52290096e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-46196356301a>:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
      "/mnt/sdb1/sandeep/miniconda3/envs/sos/lib/python3.9/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "dfs_ERC['identified_countries']=n_identified\n",
    "dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "dfs_ERC['subtract_from_n_US']=(dfs_ERC['country_awardee']=='US').astype('int')\n",
    "\n",
    "with open(path_data+'dfs_ERC_with_collab_names.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs_ERC, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5690fca-f4ed-4448-91b9-7d4e8fc08c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'       \n",
    "\n",
    "# with open(path_data+'dfs_ERC_with_collab_names.pkl', 'rb') as f:\n",
    "#     dfs_ERC=pickle.load(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fd09ad-fe09-4954-91ff-61693dde4169",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfs_ERC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64a6822b8564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Query to get career staring year for each author.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs_ERC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfs_ERC' is not defined"
     ]
    }
   ],
   "source": [
    "# Query to get career staring year for each author.\n",
    "\n",
    "dfs_ERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8e4db-47e7-46a4-b6cf-134b7870d904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
