{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fa2b98-6ee4-430d-98b6-592bf46f752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "def toc(start_time):\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(elapsed)\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import xmlschema\n",
    "from pprint import pprint\n",
    "import glob\n",
    "# importing element tree\n",
    "import lxml.etree as etree\n",
    "import pickle\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021bdac-0b83-47fc-a740-970569f0f585",
   "metadata": {},
   "source": [
    "# NSF : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00762987-9dce-47ce-8fe8-c5f444035b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2010--42---- 0.358974358974359 475.21--estimated---0.368hoursss\r"
     ]
    }
   ],
   "source": [
    "\n",
    "dict_list_NSF_collab_patterns={}\n",
    "\n",
    "for year_int in range(2010,2021):\n",
    "    year=str(year_int)\n",
    "    \n",
    "    # files_=glob.glob(path_data+'dict_NSF_careers_*')\n",
    "    files_=glob.glob(path_data+'dict_NSF_careers_'+year+'*')\n",
    "    #-----------------------------------------\n",
    "    dict_careers={}\n",
    "    for file in files_:\n",
    "        with open(file, 'rb') as f:\n",
    "            dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "    dict_list_NSF_collab_patterns[year]=[]\n",
    "    it_file=0\n",
    "    #-----------------------------------------        \n",
    "    t_ic = time.time();\n",
    "\n",
    "    for key in dict_careers.keys():     \n",
    "        it_file=it_file+1\n",
    "        scientists_nsf=list(dict_careers[key].keys())\n",
    "        # IT_=11\n",
    "        # for it_sci in range(IT_,IT_+1):\n",
    "        for it_sci in range(len(scientists_nsf)):\n",
    "            sci=scientists_nsf[it_sci]\n",
    "\n",
    "            x=json.loads(dict_careers[key][sci])\n",
    "        #     print(sci,', works count=',len(x))\n",
    "            if x!='NA':\n",
    "                for it_work in range(len(x)):\n",
    "                    paper_=x[it_work]\n",
    "            #         print(paper_.keys(),'\\n\\n')\n",
    "\n",
    "            #         print(paper_['title'],'\\n')\n",
    "            #         print('Team size=',len(paper_['authorships']))\n",
    "            #         print('pub year=',(paper_['publication_year']))\n",
    "            #         print('cited counts=',(paper_['counts_by_year']))\n",
    "\n",
    "                    affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "            #         print(affils_,'\\n\\n')\n",
    "                    countries_=[]\n",
    "\n",
    "                    for insti in affils_:\n",
    "                        if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "                            country=insti[0]['country_code']\n",
    "                            if country is None:\n",
    "                                if 'US' in insti[0]['display_name'].split(',')[-1]:\n",
    "                                    country='US'\n",
    "                            countries_.append(country)\n",
    "            #         print([insti[0]['country_code'] for insti in affils_ if len(insti)>0])\n",
    "            #         print(countries_)\n",
    "                    for y in paper_['authorships']:\n",
    "                        if 'display_name' in y['author'].keys():\n",
    "                            if y['author']['display_name']==sci:\n",
    "                                insti_main=y['institutions']\n",
    "                    try:\n",
    "                        if len(insti_main)>0:\n",
    "                            if 'country_code' in insti_main[0].keys():\n",
    "                                country_main=insti_main[0]['country_code']\n",
    "                            else:\n",
    "                                country_main=None\n",
    "                        else:\n",
    "                            country_main=None                    \n",
    "                    except:\n",
    "                        country_main=None                    \n",
    "                    try:\n",
    "                        del insti_main\n",
    "                    except:\n",
    "                        ''\n",
    "                    dict_list_NSF_collab_patterns[year].append({'scientist':sci.replace(',',''),'countries':countries_,'team_size':len(paper_['authorships']),'pub_year':paper_['publication_year'],'counts_by_year':paper_['counts_by_year'],'country_awardee':country_main})\n",
    "    #     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "        t_oc = time.time();\n",
    "        progress='progress'+'--year--   '+str(year)+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "        \n",
    "        print(progress,end='\\r')\n",
    "        with open(path_codes+\"1_df_tracker.txt\", \"w\") as file_object:\n",
    "            file_object.write(progress+'\\n')\n",
    "        \n",
    "        with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_list_NSF_collab_patterns[year], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55a82d7-a182-439b-905b-49817e1d70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"all_country_codes.txt\", \"r\")\n",
    "all_country_codes = my_file.read()\n",
    "# print(all_country_codes)\n",
    "\n",
    "all_country_codes = all_country_codes.split(\"\\n\")[1:]\n",
    "all_country_codes = [x.split(\",\") for x in all_country_codes]\n",
    "all_country_codes\n",
    "\n",
    "\n",
    "my_file = open(\"eu_codes.txt\", \"r\")\n",
    "eu_codes = my_file.read()\n",
    "eu_codes = eu_codes.split(\"\\n\")\n",
    "eu_codes = [x.split(\"-\") for x in eu_codes]\n",
    "a=[]\n",
    "for x in eu_codes:\n",
    "    b=[]\n",
    "    for y in x:\n",
    "        b.append(y.strip())\n",
    "    a.append(b)\n",
    "eu_codes = [x[0:2] for x in eu_codes]\n",
    "eu_codes_only=[x[1].strip() for x in eu_codes]\n",
    "all_country_codes_only=[x[1].strip() for x in all_country_codes]\n",
    "\n",
    "# print(all_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d14f88-7dd7-46e6-a79f-93291b617eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fdea34fdda77>:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dfs_NSF[year]['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--year--   2020--finishede\r"
     ]
    }
   ],
   "source": [
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "dict_list_NSF_collab_patterns={}\n",
    "dfs_NSF={}\n",
    "\n",
    "for year_int in range(2010,2021):\n",
    "    year=str(year_int)\n",
    "    print(year,end='\\r')\n",
    "    with open(path_data+'dict_list_NSF_collab_patterns_'+year+'.pkl', 'rb') as f:\n",
    "        dict_list_NSF_collab_patterns[year]=pickle.load(f)   \n",
    "    dfs_NSF[year]= pd.DataFrame(dict_list_NSF_collab_patterns[year])\n",
    "    dfs_NSF[year]=dfs_NSF[year].sort_values(['scientist','pub_year'],ascending=True)\n",
    "    dfs_NSF[year]=dfs_NSF[year][dfs_NSF[year]['scientist']!='- Robby']\n",
    "    countries_temp=list(dfs_NSF[year]['countries'])\n",
    "\n",
    "    n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "    dfs_NSF[year]['identified_countries']=n_identified\n",
    "    dfs_NSF[year]['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "    progress='progress'+'--year--   '+str(year)+'--n_US done'\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "    \n",
    "    dfs_NSF[year]['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "    \n",
    "    progress='progress'+'--year--   '+str(year)+'--n_EU done'\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "    \n",
    "    dfs_NSF[year]['subtract_from_n_US']=(dfs_NSF[year]['country_awardee']=='US').astype('int')\n",
    "    \n",
    "    progress='progress'+'--year--   '+str(year)+'--finished'\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"2.nsf_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "with open(path_data+'dfs_NSF.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs_NSF, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe42eeb-11ab-46e9-b30f-870007878c5a",
   "metadata": {},
   "source": [
    "# ERC : collecting countries of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8887367b-a81d-4baf-a8a4-4bacc38a5e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--119---- 1.0 898.92--estimated---0.25hoursted---0.251hours\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-0f1e16f546ff>:82: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# list_ERC_collab_patterns=[]\n",
    "\n",
    "# path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "# path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "# files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "# #-----------------------------------------\n",
    "# dict_careers={}\n",
    "# for file in files_:\n",
    "#     with open(file, 'rb') as f:\n",
    "#         dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n",
    "\n",
    "# it_file=0\n",
    "# #-----------------------------------------        \n",
    "# t_ic = time.time();\n",
    "\n",
    "# for key in dict_careers.keys():     \n",
    "#     it_file=it_file+1\n",
    "#     scientists_nsf=list(dict_careers[key].keys())\n",
    "#     # IT_=11\n",
    "#     # for it_sci in range(IT_,IT_+1):\n",
    "#     for it_sci in range(len(scientists_nsf)):\n",
    "#         sci=scientists_nsf[it_sci]\n",
    "\n",
    "#         x=json.loads(dict_careers[key][sci])\n",
    "#     #     print(sci,', works count=',len(x))\n",
    "#         if x!='NA':\n",
    "#             for it_work in range(len(x)):\n",
    "#                 paper_=x[it_work]\n",
    "#         #         print(paper_.keys(),'\\n\\n')\n",
    "\n",
    "#         #         print(paper_['title'],'\\n')\n",
    "#         #         print('Team size=',len(paper_['authorships']))\n",
    "#         #         print('pub year=',(paper_['publication_year']))\n",
    "#         #         print('cited counts=',(paper_['counts_by_year']))\n",
    "\n",
    "#                 affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#         #         print(affils_,'\\n\\n')\n",
    "#                 countries_=[]\n",
    "\n",
    "#                 for insti in affils_:\n",
    "#                     if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "#                         country=insti[0]['country_code']\n",
    "#                         countries_.append(country)\n",
    "#         #         print([insti[0]['country_code'] for insti in affils_ if len(insti)>0])\n",
    "#         #         print(countries_)\n",
    "#                 for y in paper_['authorships']:\n",
    "#                     if 'display_name' in y['author'].keys():\n",
    "#                         if y['author']['display_name']==sci:\n",
    "#                             insti_main=y['institutions']\n",
    "#                 try:            \n",
    "#                     if len(insti_main)>0:\n",
    "#                         if 'country_code' in insti_main[0].keys():\n",
    "#                             country_main=insti_main[0]['country_code']\n",
    "#                         else:\n",
    "#                             country_main=None\n",
    "#                     else:\n",
    "#                         country_main=None   \n",
    "#                 except:\n",
    "#                     country_main=None   \n",
    "#                 try:\n",
    "#                     del insti_main\n",
    "#                 except:\n",
    "#                     ''                    \n",
    "#                 list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),'countries':countries_,'team_size':len(paper_['authorships']),'pub_year':paper_['publication_year'],'counts_by_year':paper_['counts_by_year'],'country_awardee':country_main})\n",
    "# #     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "#     t_oc = time.time();\n",
    "#     progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "#     print(progress,end='\\r')\n",
    "#     with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "#         file_object.write(progress+'\\n')\n",
    "\n",
    "# dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "# dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "# countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "# n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "# dfs_ERC['identified_countries']=n_identified\n",
    "# dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "# dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "# dfs_ERC['subtract_from_n_US']=(dfs_ERC['country_awardee']=='US').astype('int')\n",
    "\n",
    "# with open(path_data+'dfs_ERC.pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs_ERC, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7235d8-23f2-4f52-b7c2-18d5bf78f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbd73c-5906-49e2-b3bd-40d3c7d57888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acb9d61d-7c6e-447f-8311-3dfbab563511",
   "metadata": {},
   "source": [
    "# ERC: collecting names of collaborators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f46e4cd-cab2-41f5-8cb3-d1b6d81967e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_ERC_collab_patterns=[]\n",
    "\n",
    "path_codes='/mnt/sdb1/sandeep/5. NSF vs ERC/codes/'\n",
    "path_data='/mnt/sdb1/sandeep/5. NSF vs ERC/data/'\n",
    "\n",
    "files_=glob.glob(path_data+'dict_careers_ERC'+'*')\n",
    "#-----------------------------------------\n",
    "dict_careers={}\n",
    "for file in files_:\n",
    "    with open(file, 'rb') as f:\n",
    "        dict_careers[file.split('/')[-1]]=pickle.load(f)                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "996c9f5c-3445-4923-8fbe-ae4bc03531ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress--119---- 1.0 971.64--estimated---0.27hoursted---0.27hourss\r"
     ]
    }
   ],
   "source": [
    "\n",
    "it_file=0\n",
    "#-----------------------------------------        \n",
    "t_ic = time.time();\n",
    "\n",
    "for key in dict_careers.keys():     \n",
    "    it_file=it_file+1\n",
    "    scientists_nsf=list(dict_careers[key].keys())\n",
    "    # IT_=11\n",
    "    # for it_sci in range(IT_,IT_+1):\n",
    "    for it_sci in range(1,len(scientists_nsf)):\n",
    "        sci=scientists_nsf[it_sci]\n",
    "#         print(sci.replace(',',''),'\\n')\n",
    "\n",
    "        x=json.loads(dict_careers[key][sci])\n",
    "    #     print(sci,', works count=',len(x))\n",
    "        if x!='NA':\n",
    "            for it_work in range(len(x)):\n",
    "                paper_=x[it_work]\n",
    "#                 print(paper_.keys(),'\\n\\n')\n",
    "#                 print(paper_['title'],'\\n')\n",
    "#                 print(paper_['authorships'])\n",
    "\n",
    "#                 affils_=[y['institutions'] for y in paper_['authorships']]\n",
    "#                 author_names_=[y['author']['display_name'] for y in paper_['authorships']]\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                author_pos_=[]\n",
    "                countries_=[]\n",
    "                author_names_=[]\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        author_names_.append(y['author']['display_name'])\n",
    "                    else:\n",
    "                        author_names_.append(None)\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'author_position' in y.keys():\n",
    "                        author_pos_.append(y['author_position'])\n",
    "                    else:\n",
    "                        author_pos_.append(None)                        \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "                for insti in affils_:\n",
    "                    if (len(insti)>0) and ('country_code' in insti[0].keys()):\n",
    "                        country=insti[0]['country_code'] ### I AM CONSIDERING ONLY THE FIRST AFFILIATION\n",
    "                        countries_.append(country)\n",
    "                    else:\n",
    "                        countries_.append(None)\n",
    "\n",
    "                for y in paper_['authorships']:\n",
    "                    if 'display_name' in y['author'].keys():\n",
    "                        if y['author']['display_name']==sci:\n",
    "                            insti_main=y['institutions']\n",
    "                try:            \n",
    "                    if len(insti_main)>0:\n",
    "                        if 'country_code' in insti_main[0].keys():\n",
    "                            country_main=insti_main[0]['country_code']\n",
    "                        else:\n",
    "                            country_main=None\n",
    "                    else:\n",
    "                        country_main=None   \n",
    "                except:\n",
    "                    country_main=None   \n",
    "                try:\n",
    "                    del insti_main\n",
    "                except:\n",
    "                    ''                    \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "                list_ERC_collab_patterns.append({'scientist':sci.replace(',',''),\n",
    "                                                 'countries':countries_,\n",
    "                                                 'team_size':len(paper_['authorships']),\n",
    "                                                 'pub_year':paper_['publication_year'],\n",
    "                                                 'counts_by_year':paper_['counts_by_year'],\n",
    "                                                 'country_awardee':country_main,\n",
    "                                                 'open_access':paper_['open_access'],\n",
    "                                                 'title':paper_['title'],\n",
    "                                                 'concepts':paper_['concepts'],\n",
    "                                                 \n",
    "                                                })\n",
    "                \n",
    "\n",
    "#     print(it_file,len(dict_careers.keys()),end='\\r')\n",
    "    \n",
    "    t_oc = time.time();\n",
    "    progress='progress'+'--'+str(it_file)+ '---- '+str(it_file/len(dict_careers.keys()))+' '+str(round(t_oc-t_ic,2))+'--estimated---'+str(round((t_oc-t_ic)/(it_file/len(dict_careers.keys()))/3600,3))+'hours'\n",
    "\n",
    "    print(progress,end='\\r')\n",
    "    with open(path_codes+\"1_df_ERC_tracker.txt\", \"w\") as file_object:\n",
    "        file_object.write(progress+'\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fdc03-f234-480f-84bd-2d52290096e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-b014db282882>:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n"
     ]
    }
   ],
   "source": [
    "dfs_ERC= pd.DataFrame(list_ERC_collab_patterns)\n",
    "\n",
    "dfs_ERC=dfs_ERC.sort_values(['scientist','pub_year'],ascending=True)\n",
    "countries_temp=list(dfs_ERC['countries'])\n",
    "\n",
    "n_identified=[len(list(filter(None, x))) for x in countries_temp]\n",
    "dfs_ERC['identified_countries']=n_identified\n",
    "dfs_ERC['n_US']=[np.sum(np.array(x)=='US') for x in countries_temp]\n",
    "dfs_ERC['n_EU']=[np.sum(np.in1d(x,eu_codes_only)) for x in countries_temp]        \n",
    "dfs_ERC['subtract_from_n_US']=(dfs_ERC['country_awardee']=='US').astype('int')\n",
    "\n",
    "with open(path_data+'dfs_ERC_with_collab_names.pkl', 'wb') as f:\n",
    "    pickle.dump(dfs_ERC, f)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5690fca-f4ed-4448-91b9-7d4e8fc08c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
